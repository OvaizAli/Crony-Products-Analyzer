{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e16d26ef",
   "metadata": {},
   "source": [
    "## Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9a9a79f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install hyperopt lightgbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a7a59028",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d13213d4",
   "metadata": {},
   "source": [
    "## Generating Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4e678cd3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'synthetic_retail_sales_2000_train.csv'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Generating a synthetic dataset based on the given schema\n",
    "np.random.seed(42)\n",
    "\n",
    "# Number of records to generate\n",
    "n_records = 2000\n",
    "\n",
    "# Product mapping to ensure logical category assignments\n",
    "product_category_mapping = {\n",
    "    'Smartphone': 'Electronics',\n",
    "    'Headphones': 'Electronics',\n",
    "    'Monitor': 'Electronics',\n",
    "    'Dining Table': 'Furniture',\n",
    "    'Board Game': 'Toys',\n",
    "    'Laptop': 'Electronics',\n",
    "    'Sofa': 'Furniture',\n",
    "    'Television': 'Electronics',\n",
    "    'Camera': 'Electronics',\n",
    "    'Watch': 'Clothing',\n",
    "    'Blender': 'Kitchen',\n",
    "    'Microwave': 'Kitchen',\n",
    "    'T-shirt': 'Clothing',\n",
    "    'Sneakers': 'Clothing',\n",
    "    'Action Figure': 'Toys',\n",
    "    'Coffee Maker': 'Kitchen',\n",
    "    'Wardrobe': 'Furniture',\n",
    "    'Bookshelf': 'Furniture',\n",
    "    'Toy Car': 'Toys'\n",
    "}\n",
    "\n",
    "# Generate the columns\n",
    "data = {\n",
    "    'Transaction ID': ['T' + str(i) for i in range(1000, 1000 + n_records)],\n",
    "    'Date': pd.date_range(start='2023-01-01', periods=n_records, freq='D'),\n",
    "    'Product Name': np.random.choice(list(product_category_mapping.keys()), n_records),\n",
    "    'Quantity Sold': np.random.randint(1, 20, n_records),\n",
    "    'Sales Price per Unit ($)': np.round(np.random.uniform(10, 1000, n_records), 2),\n",
    "    'Discount (%)': np.random.choice([0, 5, 10, 15, 20], n_records),\n",
    "    'Stock After Sale': np.random.randint(1, 500, n_records),\n",
    "    'Returned': np.random.choice([0, 1], n_records),\n",
    "    'Weather Condition': np.random.choice(['Sunny', 'Rainy', 'Cloudy', 'Snow', 'Stormy'], n_records),\n",
    "    'Temperature (Â°C)': np.round(np.random.uniform(-5, 40, n_records), 2),\n",
    "    'Humidity (%)': np.random.randint(10, 100, n_records),\n",
    "    'Precipitation (mm)': np.round(np.random.uniform(0, 50, n_records), 2),\n",
    "    'Wind Speed (km/h)': np.round(np.random.uniform(0, 100, n_records), 2),\n",
    "    'Is Holiday': np.random.choice([0, 1], n_records),\n",
    "    'Is Weekend': np.random.choice([0, 1], n_records),\n",
    "    'Is Special Event': np.random.choice([0, 1], n_records),\n",
    "    'Season': np.random.choice(['Winter', 'Spring', 'Summer', 'Fall'], n_records)\n",
    "}\n",
    "\n",
    "# Assign Category based on Product Name\n",
    "data['Category'] = [product_category_mapping[product] for product in data['Product Name']]\n",
    "\n",
    "# Convert to DataFrame\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Adjust Total Sales ($) based on quantity and price\n",
    "df['Total Sales ($)'] = df['Quantity Sold'] * df['Sales Price per Unit ($)']\n",
    "df['Total Sales After Discount ($)'] = df['Total Sales ($)'] * (1 - df['Discount (%)'] / 100)\n",
    "df['Net Sales Value ($)'] = df['Total Sales After Discount ($)'] - df['Returned'] * df['Sales Price per Unit ($)']\n",
    "\n",
    "# Creating lag features (for Quantity Sold) within each product\n",
    "df['Sales_Lag_1'] = df.groupby('Product Name')['Quantity Sold'].shift(1)\n",
    "df['Sales_Lag_7'] = df.groupby('Product Name')['Quantity Sold'].shift(7)\n",
    "df['Sales_Lag_14'] = df.groupby('Product Name')['Quantity Sold'].shift(14)\n",
    "\n",
    "# Create a future 7-day sales column as the target (simulating future sales)\n",
    "df['Future_7_Day_Sales'] = df.groupby('Product Name')['Quantity Sold'].shift(-7)\n",
    "\n",
    "# Drop the rows with NaN values due to lagging and future shifts\n",
    "df.dropna(inplace=True)\n",
    "\n",
    "# Calculate monthly sales\n",
    "df['Month'] = df['Date'].dt.to_period('M')  # Create a 'Month' column\n",
    "monthly_sales = df.groupby(['Product Name', 'Month'])['Quantity Sold'].sum().reset_index()  # Aggregate sales\n",
    "\n",
    "# Rename the aggregated column for clarity\n",
    "monthly_sales.rename(columns={'Quantity Sold': 'Monthly Sales'}, inplace=True)\n",
    "\n",
    "# Merge the monthly sales back into the original dataframe\n",
    "df = df.merge(monthly_sales, on=['Product Name', 'Month'], how='left')\n",
    "\n",
    "# Save the dataset to CSV\n",
    "file_path = 'synthetic_retail_sales_2000_train.csv'\n",
    "df.to_csv(file_path, index=False)\n",
    "\n",
    "file_path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b9fca9a",
   "metadata": {},
   "source": [
    "## Generating Testing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3bc20011",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'dict' object has no attribute 'explode'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 71\u001b[0m\n\u001b[0;32m     68\u001b[0m data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mProduct Name\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m [generate_products() \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(n_records)]\n\u001b[0;32m     70\u001b[0m \u001b[38;5;66;03m# Explode the lists of products into individual rows\u001b[39;00m\n\u001b[1;32m---> 71\u001b[0m data \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39mexplode(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mProduct Name\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     73\u001b[0m \u001b[38;5;66;03m# Remaining columns as before\u001b[39;00m\n\u001b[0;32m     74\u001b[0m data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mQuantity Sold\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mrandint(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m20\u001b[39m, \u001b[38;5;28mlen\u001b[39m(data))\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'dict' object has no attribute 'explode'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Setting a seed for reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "# Number of records to generate\n",
    "n_records = 10000\n",
    "\n",
    "# Product mapping to ensure logical category assignments\n",
    "product_category_mapping = {\n",
    "    'Smartphone': 'Gadgets',\n",
    "    'Wireless Earbuds': 'Gadgets',\n",
    "    'Gaming Monitor': 'Gaming',\n",
    "    'Coffee Table': 'Furniture',\n",
    "    'Puzzle Set': 'Toys',\n",
    "    'Gaming Laptop': 'Gaming',\n",
    "    'Recliner Chair': 'Furniture',\n",
    "    'Smart TV': 'Gadgets',\n",
    "    'Digital Camera': 'Photography',\n",
    "    'Luxury Watch': 'Accessories',\n",
    "    'Juicer': 'Kitchen Appliances',\n",
    "    'Oven': 'Kitchen Appliances',\n",
    "    'Hoodie': 'Apparel',\n",
    "    'Running Shoes': 'Apparel',\n",
    "    'Collectible Figure': 'Toys',\n",
    "    'Espresso Machine': 'Kitchen Appliances',\n",
    "    'Closet Organizer': 'Furniture',\n",
    "    'Corner Bookshelf': 'Furniture',\n",
    "    'Remote-Controlled Car': 'Toys'\n",
    "}\n",
    "\n",
    "# Generate the columns\n",
    "data = {\n",
    "    'Transaction ID': ['T' + str(i) for i in range(1000, 1000 + n_records)],\n",
    "    'Date': pd.date_range(start='2023-01-01', periods=n_records, freq='D'),\n",
    "}\n",
    "\n",
    "# Simulate product purchases with dependencies to create frequently bought products\n",
    "frequent_product_combinations = [\n",
    "    ['Smartphone', 'Wireless Earbuds'],\n",
    "    ['Gaming Laptop', 'Gaming Monitor'],\n",
    "    ['Coffee Table', 'Recliner Chair'],\n",
    "    ['Espresso Machine', 'Juicer'],\n",
    "    ['Smart TV', 'Digital Camera'],\n",
    "    ['Hoodie', 'Running Shoes'],\n",
    "    ['Puzzle Set', 'Collectible Figure'],\n",
    "    ['Oven', 'Kitchen Appliances']\n",
    "]\n",
    "\n",
    "# Create a function to generate product purchases based on combinations\n",
    "def generate_products():\n",
    "    products = []\n",
    "    # Randomly choose a combination of products\n",
    "    for combo in frequent_product_combinations:\n",
    "        if np.random.rand() < 0.3:  # 30% chance to pick a combination\n",
    "            products.extend(combo)\n",
    "    # Add some random products to ensure variety\n",
    "    additional_products = np.random.choice(\n",
    "        list(product_category_mapping.keys()), \n",
    "        size=np.random.randint(1, 3), \n",
    "        replace=False\n",
    "    )\n",
    "    products.extend(additional_products)\n",
    "    return products\n",
    "\n",
    "# Generate Product Names for each transaction\n",
    "data['Product Name'] = [generate_products() for _ in range(n_records)]\n",
    "\n",
    "# Explode the lists of products into individual rows\n",
    "data = data.explode('Product Name')\n",
    "\n",
    "# Remaining columns as before\n",
    "data['Quantity Sold'] = np.random.randint(1, 20, len(data))\n",
    "data['Sales Price per Unit ($)'] = np.round(np.random.uniform(10, 1000, len(data)), 2)\n",
    "data['Discount (%)'] = np.random.choice([0, 5, 10, 15, 20], len(data))\n",
    "data['Stock After Sale'] = np.random.randint(1, 500, len(data))\n",
    "data['Returned'] = np.random.choice([0, 1], len(data))\n",
    "data['Weather Condition'] = np.random.choice(['Sunny', 'Rainy', 'Cloudy', 'Snow', 'Stormy'], len(data))\n",
    "data['Temperature (Â°C)'] = np.round(np.random.uniform(-5, 40, len(data)), 2)\n",
    "data['Humidity (%)'] = np.random.randint(10, 100, len(data))\n",
    "data['Precipitation (mm)'] = np.round(np.random.uniform(0, 50, len(data)), 2)\n",
    "data['Wind Speed (km/h)'] = np.round(np.random.uniform(0, 100, len(data)), 2)\n",
    "data['Is Holiday'] = np.random.choice([0, 1], len(data))\n",
    "data['Is Weekend'] = np.random.choice([0, 1], len(data))\n",
    "data['Is Special Event'] = np.random.choice([0, 1], len(data))\n",
    "data['Season'] = np.random.choice(['Winter', 'Spring', 'Summer', 'Fall'], len(data))\n",
    "\n",
    "# Assign Category based on Product Name\n",
    "data['Category'] = [product_category_mapping[product] for product in data['Product Name']]\n",
    "\n",
    "# Calculate Total Sales\n",
    "data['Total Sales ($)'] = data['Quantity Sold'] * data['Sales Price per Unit ($)']\n",
    "data['Total Sales After Discount ($)'] = data['Total Sales ($)'] * (1 - data['Discount (%)'] / 100)\n",
    "data['Net Sales Value ($)'] = data['Total Sales After Discount ($)'] - data['Returned'] * data['Sales Price per Unit ($)']\n",
    "\n",
    "# Creating lag features (for Quantity Sold) within each product\n",
    "data['Sales_Lag_1'] = data.groupby('Product Name')['Quantity Sold'].shift(1)\n",
    "data['Sales_Lag_7'] = data.groupby('Product Name')['Quantity Sold'].shift(7)\n",
    "data['Sales_Lag_14'] = data.groupby('Product Name')['Quantity Sold'].shift(14)\n",
    "\n",
    "# Create a future 7-day sales column as the target (simulating future sales)\n",
    "data['Future_7_Day_Sales'] = data.groupby('Product Name')['Quantity Sold'].shift(-7)\n",
    "\n",
    "# Drop the rows with NaN values due to lagging and future shifts\n",
    "data.dropna(inplace=True)\n",
    "\n",
    "# Calculate monthly sales\n",
    "data['Month'] = data['Date'].dt.to_period('M')  # Create a 'Month' column\n",
    "monthly_sales = data.groupby(['Product Name', 'Month'])['Quantity Sold'].sum().reset_index()  # Aggregate sales\n",
    "\n",
    "# Rename the aggregated column for clarity\n",
    "monthly_sales.rename(columns={'Quantity Sold': 'Monthly Sales'}, inplace=True)\n",
    "\n",
    "# Merge the monthly sales back into the original dataframe\n",
    "df = data.merge(monthly_sales, on=['Product Name', 'Month'], how='left')\n",
    "\n",
    "# Save the dataset to CSV\n",
    "file_path = 'synthetic_retail_sales_2000_test.csv'\n",
    "df.to_csv(file_path, index=False)\n",
    "\n",
    "file_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "149adc2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# from sklearn.ensemble import RandomForestRegressor\n",
    "# from sklearn.metrics import mean_squared_error\n",
    "# from hyperopt import hp, fmin, tpe, Trials, STATUS_OK\n",
    "# import joblib\n",
    "\n",
    "# # Load your dataset\n",
    "# data = pd.read_csv('synthetic_retail_sales_2000_with_lags_rational.csv')\n",
    "\n",
    "# # Data cleaning (handle missing values, etc.)\n",
    "# data = data.dropna()\n",
    "\n",
    "# # Extract date-related features if needed (e.g., day, month)\n",
    "# data['Day'] = pd.to_datetime(data['Date']).dt.day\n",
    "# data['Month'] = pd.to_datetime(data['Date']).dt.month\n",
    "# data['Year'] = pd.to_datetime(data['Date']).dt.year\n",
    "\n",
    "# # One-hot encoding for categorical features\n",
    "# data = pd.get_dummies(data, columns=['Weather Condition', 'Season', 'Category', 'Product Name'], drop_first=True)\n",
    "\n",
    "# # Define features and target, retaining relevant sales metrics\n",
    "# features = data.drop(columns=['Transaction ID', 'Future_7_Day_Sales', 'Date'])  # Consider keeping sales metrics\n",
    "# target = data['Future_7_Day_Sales']\n",
    "\n",
    "# # Split the data into training and testing sets\n",
    "# X_train, X_test, y_train, y_test = train_test_split(features, target, test_size=0.2, random_state=42)\n",
    "\n",
    "# # Define the search space for hyperparameter optimization\n",
    "# space = {\n",
    "#     'n_estimators': hp.choice('n_estimators', [50, 100, 200]),\n",
    "#     'max_depth': hp.choice('max_depth', [None, 10, 20, 30]),  # None is acceptable, but no 0\n",
    "#     'min_samples_split': hp.randint('min_samples_split', 2, 20),\n",
    "#     'min_samples_leaf': hp.randint('min_samples_leaf', 1, 20),\n",
    "#     'max_features': hp.choice('max_features', [0.5, 0.75, 'sqrt', 'log2', None])  # Valid options\n",
    "# }\n",
    "\n",
    "# # Define the objective function for hyperparameter tuning\n",
    "# def objective(params):\n",
    "#     model = RandomForestRegressor(**params)\n",
    "#     model.fit(X_train, y_train)\n",
    "#     predictions = model.predict(X_test)\n",
    "#     mse = mean_squared_error(y_test, predictions)\n",
    "#     return {'loss': mse, 'status': STATUS_OK}\n",
    "\n",
    "# # Create a Trials object to keep track of progress\n",
    "# trials = Trials()\n",
    "\n",
    "# # Run the optimization\n",
    "# best = fmin(fn=objective,\n",
    "#             space=space,\n",
    "#             algo=tpe.suggest,\n",
    "#             max_evals=100,\n",
    "#             trials=trials)\n",
    "\n",
    "# print(\"Best hyperparameters:\", best)\n",
    "\n",
    "# # Train the final model with the best hyperparameters\n",
    "# final_model = RandomForestRegressor(**best)\n",
    "# final_model.fit(X_train, y_train)\n",
    "\n",
    "# # Make predictions on the test set\n",
    "# final_predictions = final_model.predict(X_test)\n",
    "# final_mse = mean_squared_error(y_test, final_predictions)\n",
    "# print(f'Final Mean Squared Error: {final_mse}')\n",
    "\n",
    "# # Save the model and feature names using joblib\n",
    "# joblib.dump(final_model, 'final_model.joblib')\n",
    "# joblib.dump(features.columns, 'feature_names.joblib')\n",
    "\n",
    "# # Load the model and feature names for future predictions\n",
    "# loaded_model = joblib.load('final_model.joblib')\n",
    "# loaded_feature_names = joblib.load('feature_names.joblib')\n",
    "\n",
    "# # Create new data ensuring to include the necessary categorical columns\n",
    "# new_data = pd.DataFrame({\n",
    "#     'Temperature (Â°C)': [25],\n",
    "#     'Humidity (%)': [70],\n",
    "#     'Precipitation (mm)': [0],\n",
    "#     'Wind Speed (km/h)': [10],\n",
    "#     'Is Holiday': [0],\n",
    "#     'Is Weekend': [0],\n",
    "#     'Is Special Event': [1],\n",
    "#     'Day': [15],  # Example day\n",
    "#     'Month': [7],  # Example month\n",
    "#     'Year': [2023],  # Example year\n",
    "#     'Weather Condition': ['Sunny'],\n",
    "#     'Season': ['Summer'],\n",
    "#     'Category': ['Electronics'],\n",
    "#     'Product Name': ['Smartphone'],\n",
    "# })\n",
    "\n",
    "# # One-hot encoding for categorical features in new data\n",
    "# new_data = pd.get_dummies(new_data, columns=['Weather Condition', 'Season', 'Category', 'Product Name'], drop_first=True)\n",
    "\n",
    "# # Align the new data with the trained model's features\n",
    "# new_data = new_data.reindex(columns=loaded_feature_names, fill_value=0)\n",
    "\n",
    "# # Make predictions using the loaded model\n",
    "# predictions = loaded_model.predict(new_data)\n",
    "# print(\"Predictions for new data:\", predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "201b449f",
   "metadata": {},
   "source": [
    "## Training 3 Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0ecf6dc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weekly Sales - Random Forest - MSE: 31.6137, RÂ²: -0.0799\n",
      "Weekly Sales - Gradient Boosting - MSE: 32.3608, RÂ²: -0.1054\n",
      "Weekly Sales - XGBoost - MSE: 39.6500, RÂ²: -0.3544\n",
      "Monthly Sales - Random Forest - MSE: 200.7641, RÂ²: 0.0733\n",
      "Monthly Sales - Gradient Boosting - MSE: 197.1162, RÂ²: 0.0902\n",
      "Monthly Sales - XGBoost - MSE: 227.4731, RÂ²: -0.0499\n",
      "Discount Percentage - Random Forest - MSE: 26.0438, RÂ²: 0.4749\n",
      "Discount Percentage - Gradient Boosting - MSE: 33.4112, RÂ²: 0.3263\n",
      "Discount Percentage - XGBoost - MSE: 21.9387, RÂ²: 0.5576\n",
      "Predicted Next Week's Sales: [10.12]\n",
      "Predicted Next Month's Sales: [19.49455878]\n",
      "Predicted Discount Percentage: [8.940439]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import joblib\n",
    "import xgboost as xgb\n",
    "\n",
    "# Load your dataset\n",
    "data = pd.read_csv('synthetic_retail_sales_2000_test.csv')\n",
    "\n",
    "# Data cleaning (handle missing values, etc.)\n",
    "data = data.dropna()\n",
    "\n",
    "# Extract date-related features\n",
    "data['Day'] = pd.to_datetime(data['Date']).dt.day\n",
    "data['Month'] = pd.to_datetime(data['Date']).dt.month\n",
    "data['Year'] = pd.to_datetime(data['Date']).dt.year\n",
    "\n",
    "# One-hot encoding for categorical features\n",
    "data = pd.get_dummies(data, columns=['Weather Condition', 'Season', 'Category', 'Product Name'], drop_first=True)\n",
    "\n",
    "# Prepare features and targets for each prediction task\n",
    "# Predict Next Week's Sales\n",
    "features_week = data.drop(columns=['Transaction ID', 'Future_7_Day_Sales', 'Date', 'Monthly Sales'])\n",
    "target_week = data['Future_7_Day_Sales']\n",
    "X_train_week, X_test_week, y_train_week, y_test_week = train_test_split(features_week, target_week, test_size=0.2, random_state=42)\n",
    "\n",
    "# Predict Next Month's Sales\n",
    "features_month = data.drop(columns=['Transaction ID', 'Monthly Sales', 'Date', 'Future_7_Day_Sales'])\n",
    "target_month = data['Monthly Sales']\n",
    "X_train_month, X_test_month, y_train_month, y_test_month = train_test_split(features_month, target_month, test_size=0.2, random_state=42)\n",
    "\n",
    "# Predict Discount Percentage\n",
    "features_discount = data.drop(columns=['Transaction ID', 'Discount (%)', 'Date', 'Future_7_Day_Sales', 'Monthly Sales'])\n",
    "target_discount = data['Discount (%)']\n",
    "X_train_discount, X_test_discount, y_train_discount, y_test_discount = train_test_split(features_discount, target_discount, test_size=0.2, random_state=42)\n",
    "\n",
    "# Save feature names for each model\n",
    "loaded_feature_names = {\n",
    "    'weekly': features_week.columns.tolist(),\n",
    "    'monthly': features_month.columns.tolist(),\n",
    "    'discount': features_discount.columns.tolist()\n",
    "}\n",
    "joblib.dump(loaded_feature_names, 'feature_names.joblib')\n",
    "\n",
    "# Function to evaluate models\n",
    "def evaluate_model(model, X_train, y_train, X_test, y_test):\n",
    "    model.fit(X_train, y_train)\n",
    "    predictions = model.predict(X_test)\n",
    "    mse = mean_squared_error(y_test, predictions)\n",
    "    r2 = r2_score(y_test, predictions)\n",
    "    return mse, r2\n",
    "\n",
    "# Initialize models to compare\n",
    "models = {\n",
    "    'Random Forest': RandomForestRegressor(),\n",
    "    'Gradient Boosting': GradientBoostingRegressor(),\n",
    "    'XGBoost': xgb.XGBRegressor()\n",
    "}\n",
    "\n",
    "# Store results for each model for each prediction task\n",
    "results = {'Weekly Sales': {}, 'Monthly Sales': {}, 'Discount Percentage': {}}\n",
    "best_models = {}\n",
    "\n",
    "# Evaluate models for each prediction task\n",
    "for task in ['Weekly Sales', 'Monthly Sales', 'Discount Percentage']:\n",
    "    if task == 'Weekly Sales':\n",
    "        X_train, y_train, X_test, y_test = X_train_week, y_train_week, X_test_week, y_test_week\n",
    "    elif task == 'Monthly Sales':\n",
    "        X_train, y_train, X_test, y_test = X_train_month, y_train_month, X_test_month, y_test_month\n",
    "    else:  # Discount Percentage\n",
    "        X_train, y_train, X_test, y_test = X_train_discount, y_train_discount, X_test_discount, y_test_discount\n",
    "    \n",
    "    for model_name, model in models.items():\n",
    "        mse, r2 = evaluate_model(model, X_train, y_train, X_test, y_test)\n",
    "        results[task][model_name] = {'MSE': mse, 'RÂ²': r2}\n",
    "        print(f\"{task} - {model_name} - MSE: {mse:.4f}, RÂ²: {r2:.4f}\")\n",
    "\n",
    "    # Select the best model based on MSE\n",
    "    best_model_name = min(results[task], key=lambda k: results[task][k]['MSE'])\n",
    "    best_models[task] = models[best_model_name]  # Store the best model\n",
    "\n",
    "# Train and save the best models\n",
    "for task, model in best_models.items():\n",
    "    if task == 'Weekly Sales':\n",
    "        model.fit(X_train_week, y_train_week)\n",
    "        joblib.dump(model, 'final_model_weekly_sales.joblib')\n",
    "    elif task == 'Monthly Sales':\n",
    "        model.fit(X_train_month, y_train_month)\n",
    "        joblib.dump(model, 'final_model_monthly_sales.joblib')\n",
    "    elif task == 'Discount Percentage':\n",
    "        model.fit(X_train_discount, y_train_discount)\n",
    "        joblib.dump(model, 'final_model_discount_percentage.joblib')\n",
    "\n",
    "# Load the feature names\n",
    "loaded_feature_names = joblib.load('feature_names.joblib')\n",
    "\n",
    "# Load the models for predictions\n",
    "loaded_model_weekly = joblib.load('final_model_weekly_sales.joblib')\n",
    "loaded_model_monthly = joblib.load('final_model_monthly_sales.joblib')\n",
    "loaded_model_discount = joblib.load('final_model_discount_percentage.joblib')\n",
    "\n",
    "# Create new data ensuring to include the necessary categorical columns\n",
    "new_data = pd.DataFrame({\n",
    "    'Temperature (Â°C)': [25],\n",
    "    'Humidity (%)': [70],\n",
    "    'Precipitation (mm)': [0],\n",
    "    'Wind Speed (km/h)': [10],\n",
    "    'Is Holiday': [0],\n",
    "    'Is Weekend': [0],\n",
    "    'Is Special Event': [1],\n",
    "    'Day': [15],  # Example day\n",
    "    'Month': [7],  # Example month\n",
    "    'Year': [2023],  # Example year\n",
    "    'Weather Condition': ['Sunny'],\n",
    "    'Season': ['Summer'],\n",
    "    'Category': ['Electronics'],\n",
    "    'Product Name': ['Smartphone'],\n",
    "})\n",
    "\n",
    "# One-hot encoding for categorical features in new data\n",
    "new_data = pd.get_dummies(new_data, columns=['Weather Condition', 'Season', 'Category', 'Product Name'], drop_first=True)\n",
    "\n",
    "# Make sure to align new_data with the features used during training for each model\n",
    "# For predicting weekly sales\n",
    "new_data_weekly = new_data.reindex(columns=loaded_feature_names['weekly'], fill_value=0)\n",
    "\n",
    "# For predicting monthly sales\n",
    "new_data_monthly = new_data.reindex(columns=loaded_feature_names['monthly'], fill_value=0)\n",
    "\n",
    "# For predicting discount percentage\n",
    "new_data_discount = new_data.reindex(columns=loaded_feature_names['discount'], fill_value=0)\n",
    "\n",
    "# Make predictions using the loaded models\n",
    "predicted_weekly_sales = loaded_model_weekly.predict(new_data_weekly)\n",
    "predicted_monthly_sales = loaded_model_monthly.predict(new_data_monthly)\n",
    "predicted_discount_percentage = loaded_model_discount.predict(new_data_discount)\n",
    "\n",
    "print(\"Predicted Next Week's Sales:\", predicted_weekly_sales)\n",
    "print(\"Predicted Next Month's Sales:\", predicted_monthly_sales)\n",
    "print(\"Predicted Discount Percentage:\", predicted_discount_percentage)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
